<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python爬虫学习（三）</title>
      <link href="/2025/04/16/%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%89%EF%BC%89/"/>
      <url>/2025/04/16/%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="tip"><a href="#tip" class="headerlink" title="tip"></a>tip</h3><ul><li>要是觉得找elements中对应部分有点麻烦，可以用ctrl+shift+c然后点网页你想要的部分，开发者模式中就会跳转过去了。</li></ul><h1 id="1-防盗链"><a href="#1-防盗链" class="headerlink" title="1.防盗链"></a>1.防盗链</h1><ul><li><p>现在很多网站启用了防盗链反爬，防止服务器上的资源被人恶意盗取。什么是防盗链呢？</p><ul><li>从HTTP协议说起，在HTTP协议中，有一个表头字段：referer，采用URL的格式来表示从哪一个链接跳转到当前网页的。通俗理解就是：客户端的请求具体从哪里来，服务器可以通过referer进行溯源。一旦检测来源不是网页所规定的，立即进行阻止或者返回指定的页面。</li></ul></li></ul><h1 id="2-三里屯抓拍图爬取"><a href="#2-三里屯抓拍图爬取" class="headerlink" title="2. 三里屯抓拍图爬取"></a>2. 三里屯抓拍图爬取</h1><p>网址：<a href="http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1">http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1</a><br>可以尝试按先前的方式先去爬取试试，你会发现无法爬取想要的照片，当你用开发者模式去看的时候，你会发现她有两个url，你尝试两个src会发现两个都得不到正确的图片，这就是防盗链的作用，所以我们需要再header中加入referer<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250416161705657.png" alt="image.png"><br>那么如何去找到referer呢?你需要在network中找到要爬取的图片，可以通过预览迅速辨认是否自己要找的图片，具体可按下图：<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250416165618834.png" alt="image.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line">from lxml import etree  </span><br><span class="line">url = &#x27;http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1&#x27;  </span><br><span class="line">header = &#123;  </span><br><span class="line">    &#x27;user-agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;,  </span><br><span class="line">    &#x27;referer&#x27;:&#x27;https://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1&#x27;  </span><br><span class="line">    # &quot;Referer&quot;: &quot;http://blog.sina.com.cn/&quot;  </span><br><span class="line">&#125;  </span><br><span class="line">response = requests.get(url=url,headers=header)  </span><br><span class="line">response.encoding=&#x27;utf-8&#x27;  </span><br><span class="line">page_img= response.text  </span><br><span class="line">tree = etree.HTML(page_img)  </span><br><span class="line">img_list = tree.xpath(&#x27;//*[@id=&quot;sina_keyword_ad_area2&quot;]/div/a/img/@real_src&#x27;)  </span><br><span class="line">for img in img_list:  </span><br><span class="line">    data = requests.get(url=img,headers=header).content  </span><br><span class="line">    with open(&#x27;name.jpg&#x27;,&#x27;wb&#x27;) as f:  </span><br><span class="line">        f.write(data)  </span><br><span class="line">    break</span><br></pre></td></tr></table></figure><h1 id="3-cookie"><a href="#3-cookie" class="headerlink" title="3. cookie"></a>3. cookie</h1><ul><li>什么是cookie？<ul><li>cookie的本质就是一组数据（键值对的形式存在）</li><li>是由服务器创建，返回给客户端，最终会保存在客户端浏览器中。</li><li>如果客户端保存了cookie，则下次再次访问该服务器，就会携带cookie进行网络访问。<ul><li>典型的案例：网站的免密登录</li></ul></li></ul></li></ul><h4 id="tip-1"><a href="#tip-1" class="headerlink" title="tip"></a>tip</h4><p>在通过的之前学习后，相信对于爬虫代码的基础部分已经有所掌握，对于这些开源的数据在有爬虫技术前真要获取也是可以的，比如说你一个个人工去搜集得到，但这种机械化又大量的工作正是促使爬虫技术的诞生，更进一步，一些爬虫的技术代码是否也是如此呢？据此，我想要介绍一个工具‘curlconverter’<br>网址：<a href="https://curlconverter.com/">https://curlconverter.com/</a><br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250419152947549.png" alt="image.png"><br>通过上述步骤再复制的网站中，就可得到如下一些基础的代码，也可以提高一定的效率。<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250419153118250.png" alt="image.png"></p><h2 id="案例：雪球网数据"><a href="#案例：雪球网数据" class="headerlink" title="案例：雪球网数据"></a>案例：雪球网数据</h2><p>#ps：用谷歌和edge可能会无法用开发者模式获取数据，可能是一种反爬机制，但博主用联想浏览器可以打开，并且代码可以成功运行。<br>网址：<a href="https://xueqiu.com/">https://xueqiu.com/</a><br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250419164105156.png" alt="image.png"><br>如上图一样找到curl，然后到之前的给出的网站获得对应的代码再进行修改即可，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">import</span> json  </span><br><span class="line">pages = <span class="built_in">input</span>(<span class="string">&#x27;请你输入想要爬取几页：&#x27;</span>)  </span><br><span class="line">cookies = &#123;  </span><br><span class="line">    <span class="string">&#x27;xq_a_token&#x27;</span>: <span class="string">&#x27;9773bacc11404cb5ac8b0847c564eda3730e6b61&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;xqat&#x27;</span>: <span class="string">&#x27;9773bacc11404cb5ac8b0847c564eda3730e6b61&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;xq_r_token&#x27;</span>: <span class="string">&#x27;caf75c71460c20a680e6e3c455cadcca5c1be14a&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;xq_id_token&#x27;</span>: <span class="string">&#x27;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTc0NzM1NzE4MywiY3RtIjoxNzQ1MDQ4NDMxOTI5LCJjaWQiOiJkOWQwbjRBWnVwIn0.S6DfPNTKxGAQwLt9gFPf2A16vqu5_UCPLrr5qgtlUuGnbtmGSsahB6kSe_bfpCbwvNmGgoDQ6Ot2vVDQtXwJfqWXNS8pKzskKHhed8L48G4uV0g1iX4dmrWqHFfZwwCVn3YKEH2H7dP20eU_U1FTXC8ikqHtjXPxu661rmTMGVdKG3xD5uM8DDcwZUBC6ZpetUUtzTe5To_8prNyBFujdfuUsd8zsaS-1gRCgqyiRWgQxAq204mmgo7uJ7TDWjwfYnSvg0m_JMYW8Wj7MV5ajR2dRM3XBEcNFtOWYNQi0xWhY13vt-NDZLKBWNE4mkirNtjG5cdjTO03ATJ6eYDYhg&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;cookiesu&#x27;</span>: <span class="string">&#x27;401745048477218&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;u&#x27;</span>: <span class="string">&#x27;401745048477218&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;device_id&#x27;</span>: <span class="string">&#x27;e67adc9306236a61a4c97845cd9ebec4&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Hm_lvt_1db88642e346389874251b5a1eded6e3&#x27;</span>: <span class="string">&#x27;1745048506&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;HMACCOUNT&#x27;</span>: <span class="string">&#x27;A39F3B65D44D61BF&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Hm_lpvt_1db88642e346389874251b5a1eded6e3&#x27;</span>: <span class="string">&#x27;1745048777&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;ssxmod_itna&#x27;</span>: <span class="string">&#x27;QqUOGKAK0KD5YKGQGCDhZILq7QGO1D7IDkDl4BtGRDeq7tDRDFqApYDHKjwzdsYWD1Axx4tFmAeR5DBMxbDSxD6ODK4GTpIoeWXPeDpBxIIrYQgrXorDcmeM5qwjer+pjsL/6MzpDCPGnD06x+ALbDYYLDBYD74G+DDeDi23Dj4GmDGAdNeDFGnb=gebPTxDwDB=DmkwWYPDfDDdYsBYiGlcVIeeD0qmsxo4Q+DGWGQuVW=p=DGUxRWQYx0UFDBLef/FDGu8jxguQsFQ+HbrWrPGuDG=HXQ0=jORiyli+do+qF4VbB34TK7tO7e=G4q7x1gDcfx+YqpYh80QTGGID=CE+pDDi2X=RpqiAb7Un2tYgtBa4TnG9mbg0eUeKilP7/Dd9wsmGGQe+WKHthQCD4eheWA/=xxD&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;ssxmod_itna2&#x27;</span>: <span class="string">&#x27;QqUOGKAK0KD5YKGQGCDhZILq7QGO1D7IDkDl4BtGRDeq7tDRDFqApYDHKjwzdsYWD1Axx4tFmAebDia4WEINhSngwzVbeCY2YeI3afD&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">headers = &#123;  </span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;application/json, text/plain, */*&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;origin&#x27;</span>: <span class="string">&#x27;https://xueqiu.com&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;priority&#x27;</span>: <span class="string">&#x27;u=1, i&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://xueqiu.com/&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;9&quot;, &quot;Not?A_Brand&quot;;v=&quot;8&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>: <span class="string">&#x27;&quot;Windows&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-site&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 SLBrowser/9.0.6.2081 SLBChan/103 SLBVPV/64-bit&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">l = []  </span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> pages:  </span><br><span class="line">    params = &#123;  </span><br><span class="line">        <span class="string">&#x27;page&#x27;</span>: page,  </span><br><span class="line">        <span class="string">&#x27;size&#x27;</span>: <span class="string">&#x27;10&#x27;</span>,  </span><br><span class="line">        <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;sha&#x27;</span>,  </span><br><span class="line">        <span class="string">&#x27;order_by&#x27;</span>: <span class="string">&#x27;percent&#x27;</span>,  </span><br><span class="line">        <span class="string">&#x27;order&#x27;</span>: <span class="string">&#x27;desc&#x27;</span>,  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    response = requests.get(  </span><br><span class="line">        <span class="string">&#x27;https://stock.xueqiu.com/v5/stock/screener/quote/list.json&#x27;</span>,  </span><br><span class="line">        params=params,  </span><br><span class="line">        cookies=cookies,  </span><br><span class="line">        headers=headers,  </span><br><span class="line">    )  </span><br><span class="line">    d = response.json().get(<span class="string">&#x27;data&#x27;</span>).get(<span class="string">&#x27;list&#x27;</span>)  </span><br><span class="line">    <span class="comment"># print(d)  </span></span><br><span class="line">  </span><br><span class="line">    l.extend(d)  </span><br><span class="line">    <span class="comment"># print(l)  </span></span><br><span class="line">    <span class="comment">#确保不要访问频率过快</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;list.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:  </span><br><span class="line">    fp.write(json.dumps(l, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure><p>但是虽然目前的cookie都能直接用，但实际上在主流的网站，对于cookie可能是有防备的，比如cookie可能会有有效期，或者说cookie就是一次性的，当这种情况下，对于，这样获取的cookie可能就无法成功用于代码中<br>正如先前所言，所有爬虫代码的不成功都是拟人度不够，比如说现在的代码都是根据请求头和网址直接进去数据所在的页面，但是正常流程应该是打开网站的首页，再点击之后的，所以通过代码先对主页面进行访问，浏览器会给代码一个全新的cookie，代码通过这个cookie就可以更稳定运行了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="comment"># 第一次请求  </span></span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">  </span><br><span class="line">headers = &#123;  </span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Dest&#x27;</span>: <span class="string">&#x27;document&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Mode&#x27;</span>: <span class="string">&#x27;navigate&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Site&#x27;</span>: <span class="string">&#x27;none&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-User&#x27;</span>: <span class="string">&#x27;?1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Upgrade-Insecure-Requests&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;130&quot;, &quot;Google Chrome&quot;;v=&quot;130&quot;, &quot;Not?A_Brand&quot;;v=&quot;99&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>: <span class="string">&#x27;&quot;macOS&quot;&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">url = <span class="string">&#x27;https://xueqiu.com/hq&#x27;</span>  </span><br><span class="line">response = requests.get(url, headers=headers)  </span><br><span class="line"><span class="comment"># print(response.status_code)  </span></span><br><span class="line"><span class="comment"># print(response.headers)  </span></span><br><span class="line"><span class="comment"># print(response.content)  </span></span><br><span class="line"><span class="comment"># print(response.text)  </span></span><br><span class="line"><span class="built_in">print</span>(response.cookies.get_dict())  </span><br><span class="line">c1 = response.cookies.get_dict()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第二次请求，携带动态cookie  </span></span><br><span class="line">headers = &#123;  </span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;application/json, text/plain, */*&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;cache-control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;origin&#x27;</span>: <span class="string">&#x27;https://xueqiu.com&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;priority&#x27;</span>: <span class="string">&#x27;u=1, i&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://xueqiu.com/&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;130&quot;, &quot;Google Chrome&quot;;v=&quot;130&quot;, &quot;Not?A_Brand&quot;;v=&quot;99&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>: <span class="string">&#x27;&quot;macOS&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-site&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">params = &#123;  </span><br><span class="line">    <span class="string">&#x27;page&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;size&#x27;</span>: <span class="string">&#x27;10&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;sha&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;order_by&#x27;</span>: <span class="string">&#x27;percent&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;order&#x27;</span>: <span class="string">&#x27;desc&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;md5__1632&#x27;</span>: <span class="string">&#x27;7q+xuQKDqmwOD/Wi4BKw1QDcWODO7fAeD&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">response = requests.get(  </span><br><span class="line">    <span class="string">&#x27;https://stock.xueqiu.com/v5/stock/screener/quote/list.json&#x27;</span>,  </span><br><span class="line">    params=params,  </span><br><span class="line">    cookies=c1,  </span><br><span class="line">    headers=headers,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure><p> 基于session对象实现自动处理cookie。</p><ul><li>1.创建一个空白的session对象。</li><li>2.需要使用session对象发起请求，请求的目的是为了捕获cookie<br>    - 注意：如果session对象在发请求的过程中，服务器端产生了cookie，则cookie会自动存储在session对象中。</li><li>3.使用携带cookie的session对象，对目的网址发起请求，就可以实现携带cookie的请求发送，从而获取想要的数据。</li></ul><p>注意：session对象至少需要发起两次请求</p><ul><li>第一次请求的目的是为了捕获存储cookie到session对象</li><li>后次的请求，就是携带cookie发起的请求了<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="comment"># 第一次请求  </span></span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">session = requests.session()  </span><br><span class="line">  </span><br><span class="line">headers = &#123;  </span><br><span class="line">    <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Dest&#x27;</span>: <span class="string">&#x27;document&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Mode&#x27;</span>: <span class="string">&#x27;navigate&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-Site&#x27;</span>: <span class="string">&#x27;none&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Sec-Fetch-User&#x27;</span>: <span class="string">&#x27;?1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Upgrade-Insecure-Requests&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;130&quot;, &quot;Google Chrome&quot;;v=&quot;130&quot;, &quot;Not?A_Brand&quot;;v=&quot;99&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>: <span class="string">&#x27;&quot;macOS&quot;&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">url = <span class="string">&#x27;https://xueqiu.com/hq&#x27;</span>  </span><br><span class="line"><span class="comment"># session：自动管理session  </span></span><br><span class="line">session.get(url, headers=headers)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第二次请求，携带动态cookie  </span></span><br><span class="line">headers = &#123;  </span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;application/json, text/plain, */*&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;cache-control&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="comment">#&#x27;cookie&#x27;: &#x27;u=851695628862640; HMACCOUNT=2A4FB6ADBAE70C94; cookiesu=591728562312333; device_id=ce2bbbc0e3a672b689052fc9204f8b61; xq_a_token=7716f523735d1e47a3dd5ec748923068ab8198a8; xqat=7716f523735d1e47a3dd5ec748923068ab8198a8; xq_r_token=0483ea3986e45954e03c9294444a1af14d7579d3; xq_id_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ1aWQiOi0xLCJpc3MiOiJ1YyIsImV4cCI6MTczMzEwMDgxNywiY3RtIjoxNzMxNzY2NTA1ODkyLCJjaWQiOiJkOWQwbjRBWnVwIn0.GqQPJ3wNkRxoWlb8W32s66nnlZCr9_8QhlChq5S2hdVOPBA4JcZFM2d9XaxkULzYt9KxFnDKa4dx_t4BDWfK-Bm9pV5YiheFBwvePRwnFldsSgVuw-SJBHTthJCo3wOzFkxubRyFtC248rKmuNPSaD1x7QtTHFk77O-5917lxJlip61oEZ-o1c51N31vGcQfxjzK2Do1xwPaU-3MZK_-jL3wuMZEcbRCbBTpD1GQj7PrATbajsO4Z1x7Xf58CmrLHeBz6DXIhNDf28MkxoEjSzT-mSNsCEIMXp0dbSQqhEp0D1hX3LqcCKLHebCRTiR0dMPMMIR1E_0a4-swY9Goag; Hm_lvt_1db88642e346389874251b5a1eded6e3=1731766508; is_overseas=0; ssxmod_itna=iqGxyDBiitG=KAIK0dGQDHYySeewx7IXIKAmYedND/SGIDnqD=GFDK40EoSxPd+3iYDxR3hGl7A4+F1/n8GwFoFx+OpxXSQxiTD4q07Db4GkDAqiOD7uqhoD445GwD0eG+DD4DWzqDU/fhKDjGHCcp5HAOIHfh5DbhKODiK8DYvpDAThVPYzCcxzDDapDlKhDWPODQHsAxKDExGOX+ImBxGaFfSLmbKDEj+Cmb3DvcOOG12z/xY8/txYeWpkU6nePchYYjixGn0Dzn293EDyF704dDrP3r0FkrZeee3lzYD=; ssxmod_itna2=iqGxyDBiitG=KAIK0dGQDHYySeewx7IXIKAmYedG9WMtDBL80D7prMqaG2YzxFqG7eeD; Hm_lpvt_1db88642e346389874251b5a1eded6e3=1731766579&#x27;,  </span></span><br><span class="line">    <span class="string">&#x27;origin&#x27;</span>: <span class="string">&#x27;https://xueqiu.com&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;pragma&#x27;</span>: <span class="string">&#x27;no-cache&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;priority&#x27;</span>: <span class="string">&#x27;u=1, i&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://xueqiu.com/&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;130&quot;, &quot;Google Chrome&quot;;v=&quot;130&quot;, &quot;Not?A_Brand&quot;;v=&quot;99&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>: <span class="string">&#x27;&quot;macOS&quot;&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-site&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">params = &#123;  </span><br><span class="line">    <span class="string">&#x27;page&#x27;</span>: <span class="string">&#x27;1&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;size&#x27;</span>: <span class="string">&#x27;10&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;sha&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;order_by&#x27;</span>: <span class="string">&#x27;percent&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;order&#x27;</span>: <span class="string">&#x27;desc&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;md5__1632&#x27;</span>: <span class="string">&#x27;7q+xuQKDqmwOD/Wi4BKw1QDcWODO7fAeD&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">response = session.get(  </span><br><span class="line">    <span class="string">&#x27;https://stock.xueqiu.com/v5/stock/screener/quote/list.json&#x27;</span>,  </span><br><span class="line">    params=params,  </span><br><span class="line">    headers=headers,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python爬虫学习（二）</title>
      <link href="/2025/04/15/%E7%88%AC%E8%99%AB%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>/2025/04/15/%E7%88%AC%E8%99%AB%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h3><ul><li>爬虫相关案例不会详细到一步步放出来，比如获取多个页面的数据，你就去多看几个页面的网址，大概率就能发现他的规律，又或者先获取当前页面的跳转网址，在对获取到的网址再做一次类似的爬取，很多就是一步步轮下去的，而我呈现的是完整的一步到位的代码，所以感觉有跳跃或者有问题，可以勤用print，可以较为直观的看出是哪里有问题。</li></ul><h1 id="1、数据解析"><a href="#1、数据解析" class="headerlink" title="1、数据解析"></a>1、数据解析</h1><p>上篇中的案例其实主要都是在进行通用爬虫，但对于用户来说，爬取整个页面的信息是冗余的，许多信息是无用数据甚至还需要用户自行去挑选，需要耗费大量的时间和精力，所以数据解析就显得无可或缺。</p><p>数据解析的概念：可以将爬取到的数据中指定的数据进行单独提取<br>作用：实现聚焦爬虫<br><strong>通用原理：</strong></p><ul><li>在一张页面中，爬取到的数据往往存储于html文件中</li><li>html文件中，可以通过标签去定位想要获取的数据位置，并进行提取<br><strong>数据解析技术：</strong></li><li>xpath（通用性最强）</li><li>bs4（python独有，学习成本低）</li><li>正则表达式（复杂度高）</li><li>pyquery（css语句）<br><strong>这次主要以xpath技术为主，xpath的编码流程：</strong></li><li>创建一个etree类型的对象，把被解析的数据加载到该对象中</li><li>调用etree对象中的xpath函数结合不同形式的xpath表达式进行数据提取</li></ul><h2 id="2-案例一"><a href="#2-案例一" class="headerlink" title="2.案例一"></a>2.案例一</h2><p>通过新建一个text.html文件，对html进行分析来初步理解xpath进行数据解析的原理</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">title</span>&gt;</span>测试bs4<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>百里守约<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;song&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>李清照<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>王安石<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>苏轼<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>柳宗元<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.song.com/&quot;</span> <span class="attr">title</span>=<span class="string">&quot;赵匡胤&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_self&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">span</span>&gt;</span>this is span<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">     宋朝是最强大的王朝，不是军队的强大，而是经济很强大，国民都很有钱<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;du&quot;</span>&gt;</span>总为浮云能蔽日,长安不见使人愁<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;http://www.baidu.com/meinv.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;tang&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.baidu.com&quot;</span> <span class="attr">title</span>=<span class="string">&quot;qing&quot;</span>&gt;</span>清明时节雨纷纷,路上行人欲断魂,借问酒家何处有,牧童遥指杏花村<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.163.com&quot;</span> <span class="attr">title</span>=<span class="string">&quot;qin&quot;</span>&gt;</span>秦时明月汉时关,万里长征人未还,但使龙城飞将在,不教胡马度阴山<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.126.com&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;qi&quot;</span>&gt;</span>岐王宅里寻常见,崔九堂前几度闻,正是江南好风景,落花时节又逢君<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.sina.com&quot;</span> <span class="attr">class</span>=<span class="string">&quot;du&quot;</span>&gt;</span>杜甫<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.dudu.com&quot;</span> <span class="attr">class</span>=<span class="string">&quot;du&quot;</span>&gt;</span>杜牧<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>杜小月<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">i</span>&gt;</span>度蜜月<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.haha.com&quot;</span> <span class="attr">id</span>=<span class="string">&quot;feng&quot;</span>&gt;</span>凤凰台上凤凰游,凤去台空江自流,吴宫花草埋幽径,晋代衣冠成古丘<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>代码中我们需要使用一个新的包lxml,可以通过下述在终端中进行下载</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#先创建一个etree对象，把数据加载到etree中去  </span></span><br><span class="line">tree = etree.parse(<span class="string">&#x27;test.html&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#对数据进行提取  </span></span><br><span class="line"><span class="comment">#xpath函数返回的是列表，列表中存储的是满足定位要求的所有标签  </span></span><br><span class="line"><span class="comment">#具体获取html下的head中的title  </span></span><br><span class="line">ret = tree.xpath(<span class="string">&#x27;/html/head/title&#x27;</span>)  </span><br><span class="line"><span class="comment">#   ‘//’获取所有的title  </span></span><br><span class="line">ret1 = tree.xpath(<span class="string">&#x27;//title&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#对&lt;body&gt;中的数据进行提取,你会发现有多个&lt;div&gt;  </span></span><br><span class="line">ret2 = tree.xpath(<span class="string">&#x27;//div&#x27;</span>) <span class="comment">#获取所有的div  </span></span><br><span class="line">ret3 = tree.xpath(<span class="string">&#x27;//div[@class=&quot;song&quot;]&#x27;</span>) <span class="comment">#获取class为song的数据  </span></span><br><span class="line">ret4 = tree.xpath(<span class="string">&#x27;//div[@class=&quot;song&quot;]/p&#x27;</span>)<span class="comment">#获取该div下的p标签数据  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment">#运行之后你会发现他给的都是&lt;Element p at 0x2555a90de80&gt;这样的数据  </span></span><br><span class="line"><span class="comment">#如果要获得文本数据，则需要使用text()  </span></span><br><span class="line">ret5 = tree.xpath(<span class="string">&#x27;//a[@id=&quot;feng&quot;]/text()&#x27;</span>) <span class="comment">#提取对应a中的数据  </span></span><br><span class="line">ret6 = tree.xpath(<span class="string">&#x27;//a//text()&#x27;</span>) <span class="comment">#提取a下所有的文本数据  </span></span><br><span class="line"><span class="comment">#总结：/text（）提取对应下的文本，//text()提取所有的文本  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment">#提取标签的属性值，比如图片地址 //tag/@attrNameret7 = tree.xpath(&#x27;//img/@src&#x27;)  </span></span><br><span class="line"><span class="built_in">print</span>(ret7)</span><br></pre></td></tr></table></figure><h2 id="3-碧血剑小说"><a href="#3-碧血剑小说" class="headerlink" title="3. 碧血剑小说"></a>3. 碧血剑小说</h2><p>网址：<a href="https://www.jinyongwang.net/bi/">https://www.jinyongwang.net/bi/</a><br>结果：将各个章节的标题和内容进行爬取然后存储到文件中<br>先找到对应的标签的位置<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250415201422830.png" alt="image.png"><br>然后右键<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250415203632155.png" alt="image.png"><br>即可复制xpath，减少工作量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree  </span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin  </span><br><span class="line">  </span><br><span class="line">url =<span class="string">&#x27;https://www.jinyongwang.net/bi/&#x27;</span>  </span><br><span class="line">header = &#123;  </span><br><span class="line"><span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line"><span class="string">&#x27;referer&#x27;</span>:<span class="string">&#x27;https://www.jinyongwang.net/bi/&#x27;</span>,  </span><br><span class="line"><span class="string">&#x27;cookie&#x27;</span>: <span class="string">&#x27;PHPSESSID=t880k0dcvvjkbgdulcaa25krf6&#x27;</span>  </span><br><span class="line">&#125;  </span><br><span class="line">response = requests.get(url=url,headers=header)  </span><br><span class="line">response.encoding=<span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">page_bi = response.text  </span><br><span class="line"><span class="comment"># 上述代码是和之前差不多的  </span></span><br><span class="line"><span class="comment">#但与前一个案例不同，因为这是requests得到数据不是html文件所以不是parse  </span></span><br><span class="line">tree = etree.HTML(page_bi)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># f = open(&#x27;bixuejian.txt&#x27;,&#x27;w&#x27;)  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;bixuejian.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    li_list = tree.xpath(<span class="string">&#x27;//*[@id=&quot;pu_box&quot;]/div[3]/ul/li&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:  </span><br><span class="line">        <span class="comment">#局部标签，只在li中寻找,因为xpath得到的是列表，  </span></span><br><span class="line">        <span class="comment"># 所以还得[0]是为了得到字符串  </span></span><br><span class="line">        title = li.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]  </span><br><span class="line">        detail = li.xpath(<span class="string">&#x27;./a/@href&#x27;</span>)[<span class="number">0</span>]  </span><br><span class="line">        detail_url = urljoin(url, detail)  </span><br><span class="line">        res = requests.get(url=detail_url,headers=header )  </span><br><span class="line">        res.encoding= <span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">        content = res.text  </span><br><span class="line">        detail_tree = etree.HTML(content)  </span><br><span class="line">        text = detail_tree.xpath(<span class="string">&#x27;//*[@id=&quot;vcon&quot;]//p//text()&#x27;</span>)  </span><br><span class="line">        text_join  = <span class="string">&#x27;,\n&#x27;</span>.join(text).strip()  </span><br><span class="line">        <span class="comment"># print(text_join)  </span></span><br><span class="line">        <span class="comment"># f.write(title+&#x27;:&#x27;+ text_join+&#x27;\n&#x27;)        f.write(f&quot;&#123;title&#125;: &#123;text_join&#125;\n&quot;)  </span></span><br><span class="line">        <span class="built_in">print</span>(title + <span class="string">&#x27;  下载成功&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250416085353234.png" alt="image.png"><br>上述就是结果样式</p><h2 id="4-简历爬取"><a href="#4-简历爬取" class="headerlink" title="4. 简历爬取"></a>4. 简历爬取</h2><p>网址&#x3D; <a href="https://sc.chinaz.com/jianli/">https://sc.chinaz.com/jianli/</a><br>下述就是需要得到的xpath<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250416105606192.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree  </span><br><span class="line">  </span><br><span class="line">page_input = <span class="built_in">input</span>(<span class="string">&#x27;请输入搜索页码（1-5）：&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">pages=[]  </span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;-&#x27;</span> <span class="keyword">in</span> page_input:  </span><br><span class="line">    start,end = <span class="built_in">map</span>(<span class="built_in">int</span>, page_input.split(<span class="string">&#x27;-&#x27;</span>))  </span><br><span class="line">    pages= <span class="built_in">list</span>(<span class="built_in">range</span>(start, end+<span class="number">1</span>))  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    pages = [<span class="built_in">int</span>(page_input)]  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> (<span class="number">1</span>,<span class="number">2</span>):  </span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:  </span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/jianli/index.html&#x27;</span>  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/jianli/index_%d.html&#x27;</span>%page  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;当前正在爬取第%d页的数据&#x27;</span>%page)  </span><br><span class="line">    header = &#123;  </span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">    response = requests.get(url=url, headers=header)  </span><br><span class="line">    response.encoding=<span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">    page_jianli = response.text  </span><br><span class="line">    tree = etree.HTML(page_jianli)  </span><br><span class="line">    div_list = tree.xpath(<span class="string">&#x27;//*[@id=&quot;container&quot;]/div&#x27;</span>)  </span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> div_list:  </span><br><span class="line">        title = div.xpath(<span class="string">&#x27;./p/a/text()&#x27;</span>)[<span class="number">0</span>]  </span><br><span class="line">        detail_url = div.xpath(<span class="string">&#x27;./a/@href&#x27;</span>)[<span class="number">0</span>]  </span><br><span class="line">        jianli_response = requests.get(url=detail_url,headers=header)  </span><br><span class="line">        jianli_response.encoding= <span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">        page_down = jianli_response.text  </span><br><span class="line">        <span class="comment">#创建etree对象，将数据存入对象中  </span></span><br><span class="line">        down_tree = etree.HTML(page_down)  </span><br><span class="line">        <span class="comment">#通过标签定位获取数据  </span></span><br><span class="line">        down_url = down_tree.xpath(<span class="string">&#x27;//*[@id=&quot;down&quot;]/div[2]/ul/li[1]/a/@href&#x27;</span>)[<span class="number">0</span>]  </span><br><span class="line">        down_response = requests.get(url=down_url,headers=header)  </span><br><span class="line">        down_content = down_response.content  </span><br><span class="line">        name = <span class="string">&#x27;./jianli/&#x27;</span>+ title+ <span class="string">&#x27;.rar&#x27;</span>  </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(name,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">            f.write(down_content)</span><br></pre></td></tr></table></figure><p><strong>ps（pthon）</strong></p><ul><li>序列化：json.dumps()</li><li>反序列化：json.load()</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python爬虫学习（一）</title>
      <link href="/2025/04/13/python%E7%88%AC%E8%99%AB/"/>
      <url>/2025/04/13/python%E7%88%AC%E8%99%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h1><p>本篇开始想要从基础的爬虫案例开始，逐步完成爬虫相关技术的学习，在本篇中，我会用东方财富 、51游戏、中国人事考试网等案例进行，从易到难。</p><h1 id="2-爬虫功能分类"><a href="#2-爬虫功能分类" class="headerlink" title="2.爬虫功能分类"></a>2.爬虫功能分类</h1><p>在进行案例之前先说明一下爬虫的功能分类，一共有如下几种</p><ul><li>通用爬虫：直接对页面的所有数据进行爬取</li><li>聚焦爬虫：对页面中的数据有选择性的爬取</li><li>功能爬虫：通过浏览器或者app实现自动化爬取</li><li>增量式爬虫：对新更新的数据进行补充爬取，以前爬取的数据不再新爬取</li><li>分布式爬虫：搭建分布式集群对网络资源进行联合且分布的爬取<br>当然本篇的案例只是很基础的案例，甚至代码都不会多</li></ul><h1 id="3-1-东方财富网"><a href="#3-1-东方财富网" class="headerlink" title="3.1 东方财富网"></a>3.1 东方财富网</h1><p>网址：<a href="https://www.eastmoney.com/">https://www.eastmoney.com/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests </span><br><span class="line">url = <span class="string">&#x27;https://www.eastmoney.com/&#x27;</span></span><br><span class="line"><span class="comment">#向指定URL进行请求，响应数据</span></span><br><span class="line">response = requests.get(url =url) </span><br><span class="line">response.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">page = response.text <span class="comment">#text返回的是字符串的响应数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;dongfang.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp: </span><br><span class="line"><span class="comment">#如果返回还有编码问题，在open中也加个 encoding=&#x27;utf-8&#x27; </span></span><br><span class="line">fp.write(page) <span class="comment">#这里的page是上述获取的响应数据</span></span><br></pre></td></tr></table></figure><p>通过运行上方代码即可得到，下述内容的文件<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/blog/Pasted%20image%2020250414090650.png"><br>在右上角四个浏览器中选择一个进入即可看到爬取成果</p><h1 id="3-2-51游戏网"><a href="#3-2-51游戏网" class="headerlink" title="3.2 51游戏网"></a>3.2 51游戏网</h1><p>网址：<a href="https://www.51.com/">https://www.51.com/</a><br>上一个案例中，只是简单的对url的首页进行通用爬取，但事实上你进入一个网站肯定不会只因为其主页，比如这个游戏网，你若想搜集带有“王者”这个关键词的游戏仅靠先前给出代码无法实现该需求<br>此时可以先进入网页去搜索看看相关的网址会是什么样<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-04-14%20095515.png" alt="屏幕截图 2025-04-14 095515.png"><br>通过类似输入多个关键词，会发现url前面<a href="https://game.51.com/search/action/game/%E9%83%BD%E6%B2%A1%E6%9C%89%E6%94%B9%E5%8F%98%EF%BC%8C%E5%8F%AA%E6%9C%89%E5%90%8E%E9%9D%A2%E7%9A%84%22%E7%8E%8B%E8%80%85%22%E8%BF%99%E4%B8%AA%E5%85%B3%E9%94%AE%E8%AF%8D%E5%8F%98%E5%8C%96%E4%BA%86%EF%BC%8C%E6%89%80%E4%BB%A5%E5%AF%B9%E5%BA%94%E7%9A%84%E4%BB%A3%E7%A0%81%E4%B9%9F%E4%BC%9A%E5%AF%B9%E5%BA%94%E5%8F%98%E5%8C%96">https://game.51.com/search/action/game/都没有改变，只有后面的&quot;王者&quot;这个关键词变化了，所以对应的代码也会对应变化</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">  </span><br><span class="line">game_title = <span class="built_in">input</span>(<span class="string">&#x27;请输入想要搜索的关键词：&#x27;</span>)  </span><br><span class="line"><span class="comment">#存放需要的请求参数</span></span><br><span class="line">params = &#123;  </span><br><span class="line">  <span class="string">&#x27;q&#x27;</span>: game_title  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">url= <span class="string">&quot;https://www.51.com/&quot;</span>  </span><br><span class="line"><span class="comment">#这是搜索的网址头</span></span><br><span class="line">first_url = <span class="string">&#x27;https://game.51.com/search/action/game/&#x27;</span>  </span><br><span class="line">response = requests.get(url=first_url,params=params)  </span><br><span class="line">response.encoding = <span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">page_51 = response.text  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;51.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:  </span><br><span class="line">    fp.write(page_51)</span><br></pre></td></tr></table></figure><h1 id="3-3-中国人事考试网"><a href="#3-3-中国人事考试网" class="headerlink" title="3.3 中国人事考试网"></a>3.3 中国人事考试网</h1><ul><li>网址 <a href="http://www.cpta.com.cn/">http://www.cpta.com.cn/</a><br>如果你根据先前的代码去进行爬取，并不会报错，但是当你将爬取到的网址打开以后并不会得到对应网址，而是如下图的报错。<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414103956791.png" alt="image.png"></li></ul><p>于是据此，提出一个说法，对于此类问题都是由于爬虫模拟浏览器的程度不够，网站认为我的这个id不正常，不属于正常用户访问浏览器的id所以无法进行爬取，所以，我们需要在代码中加入header，也就是请求头，你可以通过在浏览器中按F12，进入开发者模式<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414104534207.png" alt="image.png"><br>请求标头的就是正常用户提出请求会携带的数据，而先前的代码中并没有这些，所谓的反爬机制就是这样找到你模拟不够完善的地方，然后组织爬虫代码访问，但并不是说请求头中的所有都需要填进去，多数仅需要UA和cookie就可以使得代码正常运行(对应数据按照上述图去找到复制即可)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">url = <span class="string">&#x27;http://www.cpta.com.cn/&#x27;</span>  </span><br><span class="line">header = &#123;  </span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;</span>  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">response = requests.get(url=url,headers=header)  </span><br><span class="line">response.encoding= <span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">page_cpta = response.text  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cpta.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding= <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    f.write(page_cpta)</span><br></pre></td></tr></table></figure><p>当然获取的文件中可能会只包含数据，一些网站的设计排版不一定会有，但数据爬到就可以了<br>如果我们想要更进一步搜索，比如想搜“人力资源”相关的信息，肯定还需要另外的代码，在写之前可以去实际网页搜索试试，看看网址有什么关系<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414110930404.png" alt="image.png"><br>你会发现这个页面和之前的51游戏页面有有所不同这里的网址值只有search，无论你搜什么关键词，网址都只是这个，此时你可以打开F12，查看相关信息，你会发现与之前的请求方式不同，这个页面采用的是post请求方式<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414111517102.png" alt="image.png"><br>post数据往往会返回数据存储在json文件中，所以你应当去找对应的数据，也就是标头右边的载荷<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414111636320.png" alt="image.png"><br>将这里的数据复制到代码中再进行爬虫就可以达成效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">url = <span class="string">&#x27;http://www.cpta.com.cn/category/search&#x27;</span>  </span><br><span class="line">key_word = <span class="built_in">input</span>(<span class="string">&#x27;请输入想要搜索的关键词：&#x27;</span>)  </span><br><span class="line">params = &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="string">&#x27;keywords&#x27;</span>: key_word ,  </span><br><span class="line">    <span class="string">&#x27;搜 索&#x27;</span>: <span class="string">&#x27;搜 索&#x27;</span>  </span><br><span class="line">&#125;  </span><br><span class="line">header = &#123;  </span><br><span class="line"><span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;</span>,  </span><br><span class="line">&#125;  </span><br><span class="line">response = requests.post(url= url,headers=header, params=params)  </span><br><span class="line">response.encoding=<span class="string">&#x27;utf=8&#x27;</span>  </span><br><span class="line">page_cpta = response.text  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cpta_search.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    f.write(page_cpta)</span><br></pre></td></tr></table></figure><h1 id="4-KFC餐厅"><a href="#4-KFC餐厅" class="headerlink" title="4. KFC餐厅"></a>4. KFC餐厅</h1><ul><li>网址：<a href="http://www.kfc.com.cn/kfccda/storelist/index.aspx">http://www.kfc.com.cn/kfccda/storelist/index.aspx</a><br>在这里你若是想要通过关键词去进行查询你会发现，它并不会挑跳转到新网址，但是你若是按原本网址来却只能获取到无搜索时的数据。<br>这是因为在页面数据中有一种数据名为动态数据，动态加载数据值不是直接通过浏览器地址栏的url请求到的数据，这些数据叫做动态加载数据。<br>那么怎么判别数据是否是动态数据呢？你可以通过开发者模式，进入到当前页面的network<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414120018745.png" alt="image.png"><br>查找窗口可以通过ctrl+f 进行呼出，输入关键词，然后在响应中去搜索关键词看看是否能找到对应的数据，若无贼说明是动态数据<br>可以通过动态数据左上角的全局搜索进行找到对应文件<br><img src="https://image-1352611653.cos.ap-guangzhou.myqcloud.com/img/20250414120958787.png" alt="image.png"><br>动态数据往往会用json存储，所以写代码的时候得留意，并且数据往往不止一页，有多页，需要采取多页连续采取<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line">key_word = <span class="built_in">input</span>(<span class="string">&#x27;请输入关键词:&#x27;</span>)  </span><br><span class="line">page_input = <span class="built_in">input</span>(<span class="string">&#x27;请输入页码(如1-5或1,2,3)：&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">pages=[]  </span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;-&#x27;</span> <span class="keyword">in</span> page_input:  </span><br><span class="line">    start,end = <span class="built_in">map</span>(<span class="built_in">int</span>, page_input.split(<span class="string">&#x27;-&#x27;</span>))  </span><br><span class="line">    pages= <span class="built_in">list</span>(<span class="built_in">range</span>(start, end+<span class="number">1</span>))  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    pages = [<span class="built_in">int</span>(page_input)]  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;kfc1.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    f.write(<span class="string">&quot;门店名称\t地址\n&quot;</span>)  <span class="comment"># 写入表头  </span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> pages:  </span><br><span class="line">        url = <span class="string">&#x27;http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=keyword&#x27;</span>  </span><br><span class="line">        header = &#123;  </span><br><span class="line">        <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36&#x27;</span>  </span><br><span class="line">        &#125;  </span><br><span class="line">        data = &#123;  </span><br><span class="line">            <span class="string">&#x27;cname&#x27;</span>:<span class="string">&#x27;&#x27;</span> ,  </span><br><span class="line">             <span class="string">&#x27;pid&#x27;</span>: <span class="string">&#x27;&#x27;</span>,  </span><br><span class="line">            <span class="string">&#x27;keyword&#x27;</span>: key_word,  </span><br><span class="line">            <span class="string">&#x27;pageIndex&#x27;</span>: page,  </span><br><span class="line">            <span class="string">&#x27;pageSize&#x27;</span>: <span class="string">&#x27;10&#x27;</span>  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        response = requests.post(url=url,headers=header,data=data)  </span><br><span class="line">        response.encoding= <span class="string">&#x27;utf-8&#x27;</span>  </span><br><span class="line">        page_KFC = response.json()  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">for</span> detail <span class="keyword">in</span> page_KFC[<span class="string">&#x27;Table1&#x27;</span>]:  </span><br><span class="line">            storename = detail.get(<span class="string">&#x27;storeName&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>)  </span><br><span class="line">            add = detail.get(<span class="string">&#x27;addressDetail&#x27;</span>, <span class="string">&#x27;N/A&#x27;</span>)  </span><br><span class="line">            f.write(<span class="string">f&quot;<span class="subst">&#123;storename&#125;</span>\t<span class="subst">&#123;add&#125;</span>\n&quot;</span>)  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;成功保存：<span class="subst">&#123;storename&#125;</span>-<span class="subst">&#123;add&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/css/transpancy.css"/>
      <url>/css/transpancy.css</url>
      
        <content type="html"><![CDATA[/* 1. 容器对齐与间距 */.layout>div:first-child:not(.recent-posts) {    -webkit-align-self: flex-start;    align-self: flex-start;    -ms-flex-item-align: start;    padding: 50px 40px;}/* 2. 侧边栏卡片宽度控制 */#aside-content #card-toc .toc-content {    width: 340px;}#aside-content #card-toc .toc-content .toc-link {    font-size: 16px;}#aside-content .card-announcement .item-headline i {    color: rgb(53, 183, 41);}/*è¿™é‡Œæ”¾å¤–æ¡†*//* body{    cursor:url(https://cdn.custom-cursor.com/db/5006/32/arrow2836.png) , default!important;    }    /*è¿™é‡Œæ”¾å†…æ¡†*//* a,img,button{    cursor: url(https://cdn.custom-cursor.com/db/5005/32/arrow2836.png) , pointer !important;    } */ */ .aplayer .aplayer-list ol li.aplayer-list-light, .aplayer, #aside_content .card-widget, .layout>div:first-child:not(.recent-posts), .layout_post>#page, .layout_post>#post, .read-mode .layout_post>#post{    /* ä»¥ä¸‹ä»£è¡¨ç™½è‰²é€æ˜Žåº¦ä¸º0.3 */    background: rgba(255, 255, 255, 0.9);    border:2px solid #0ff5ff;    box-shadow: 1px 1px 10px #0ff5ff;}/* 目录子元素样式​ */toc-child {    font-size: 10px;}/* 1. 背景与整体布局 */#post .post-copyright {    background: rgba(231, 252, 253, 0.9);}/* 元数据样式 */#post .post-copyright .post-copyright-meta {    color: #21597d;    font-weight: bold;}/* 正文内容样式 */#post .post-copyright .post-copyright-info {    padding-left: 6px;    color: #5274ba;}/* 4. 链接样式 */#post .post-copyright .post-copyright-info a {    padding-left: 6px;    color: #4b8de8}/* 页面容器样式​ */#git_container,#archive,#page {    background: rgba(214, 242, 244, 0.8);    /* 半透明浅蓝背景 */    border: 2px solid #0ff5ff !important;    /* 青色边框 */    box-shadow: 1px 1px 20px #0ff5ff !important;    /* 浅蓝投影 */}/* ​​卡片组件样式 */.card-widget {    border: 2px solid #3d0f3f00 !important;    /* 透明深灰边框 */    box-shadow: 1px 1px 20px #c4e8fc !important;    /* 浅蓝投影 */    --font-color: #2e8086;    /* 定义字体色变量 */    --text-highlight-color: #110101;    /* 定义高亮色变量 */}/* 暗色模式适配​ */[data-theme='dark'] {    --font-color: black;    --text-highlight-color: #fdeacc;}标题样式​ #subtitle,#site-title {    color: #ffffff !important;}.layout_page>div:first-child:not(.recent-posts),.layout_post>#page,.layout_post>#post,.read-mode .layout_post>#post {    background: var(--light_bg_color)}#aside-content .card-info .author-info__name {    font-weight: 500;    font-size: 2.57em;    color: #ffffff;}/* ç®€ä»‹ */#aside-content .card-info .author-info__description {    margin-top: -0.42em;    font-size: 1.30em;    color: #000000;}/* 边栏文章等 */.site-data>a .headline {    font-size: 20px;    color: #21597d;}/* 边栏文章等的数字 */.site-data>a .length-num {    margin-top: -0.32em;    color: var(--text-highlight-color);    font-size: 1.4em;}/* å¾®ä¿¡ */#aside-content .card-widget.card-announcement {    background-color: #a2d1b2;}/* ç›®å½• */#aside-content #card-toc {    background-color: #f5e9eb;}/* æœ€è¿‘æ–‡ç«  */#aside-content .card-widget.card-recent-post {    background-color: #e2ebda;}/* ç½‘ç«™ä¿¡æ¯ */#aside-content .card-widget.card-webinfo {    background-color: #c7c7c6;}/* å¾®åšä¿¡æ¯ */#weibo.card-widget {    background: linear-gradient(to right, #ff5f6d, #ffc371);    /* æ·»åŠ å…¶ä»–æ ·å¼ */    border-radius: 10px;    color: #0ff5ff ;    border-width: 10px;}@-webkit-keyframes Gradient {    0% {        background-position: 0% 50%;    }    50% {        background-position: 100% 50%;    }    100% {        background-position: 0% 50%;    }}@-moz-keyframes Gradient {    0% {        background-position: 0% 50%;    }    50% {        background-position: 100% 50%;    }    100% {        background-position: 0% 50%;    }}@keyframes Gradient {    0% {        background-position: 0% 50%;    }    50% {        background-position: 100% 50%;    }    100% {        background-position: 0% 50%;    }}/* ä¸ªäººä¿¡æ¯Follow meæŒ‰é’® */#aside-content>.card-widget.card-info>#card-info-btn {    background-color: #3eb8be;    border-radius: 8px;}/* æ³¢æµª *//* æ³¢æµªcss */.main-hero-waves-area {    width: 100%;    position: absolute;    left: 0;    bottom: -11px;    z-index: 5;}.waves-area .waves-svg {    width: 100%;    height: 5rem;}/* Animation */.parallax>use {    animation: move-forever 25s cubic-bezier(0.55, 0.5, 0.45, 0.5) infinite;}.parallax>use:nth-child(1) {    animation-delay: -2s;    animation-duration: 7s;    fill: #f7f9febd;}.parallax>use:nth-child(2) {    animation-delay: -3s;    animation-duration: 10s;    fill: #f7f9fe82;}.parallax>use:nth-child(3) {    animation-delay: -4s;    animation-duration: 13s;    fill: #f7f9fe36;}.parallax>use:nth-child(4) {    animation-delay: -5s;    animation-duration: 20s;    fill: #f7f9fe;}/* é»‘è‰²æ¨¡å¼èƒŒæ™¯ */[data-theme="dark"] .parallax>use:nth-child(1) {    animation-delay: -2s;    animation-duration: 7s;    fill: #18171dc8;}[data-theme="dark"] .parallax>use:nth-child(2) {    animation-delay: -3s;    animation-duration: 10s;    fill: #18171d80;}[data-theme="dark"] .parallax>use:nth-child(3) {    animation-delay: -4s;    animation-duration: 13s;    fill: #18171d3e;}[data-theme="dark"] .parallax>use:nth-child(4) {    animation-delay: -5s;    animation-duration: 20s;    fill: #18171d;}/* 1. 波浪动画 */@keyframes move-forever {    0% {        transform: translate3d(-90px, 0, 0);    }    100% {        transform: translate3d(85px, 0, 0);    }}/*Shrinking for mobile*/@media (max-width: 768px) {    .waves-area .waves-svg {        height: 40px;        min-height: 40px;    }}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>关于我</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>电影</title>
      <link href="/movies/index.html"/>
      <url>/movies/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>小说</title>
      <link href="/novels/index.html"/>
      <url>/novels/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>友情链接</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* 导航栏模块 *//* 一级菜单居中 */#nav .menus_items {    position: absolute !important;    width: fit-content !important;    left: 50% !important;    transform: translateX(-50%) !important;    font-size: 25px !important; /* 独立于全局字体 */      }/* 子菜单横向展示 */#nav .menus_items .menus_item:hover .menus_item_child {    display: row !important;}/* 这里的2是代表导航栏的第2个元素，即有子菜单的元素，可以按自己需求修改 */.menus_items .menus_item:nth-child(5) .menus_item_child {    left: -50px;}/* 背景的通明度模块 *//* 文章页背景 */.layout_post>#post {    /* 以下代表透明度为0.7 可以自行修改*/    background: rgba(255,255,255,.9);} /* 所有页面背景 */#aside_content .card-widget, #recent-posts>.recent-post-item, .layout_page>div:first-child:not(.recent-posts), .layout_post>#page, .layout_post>#post, .read-mode .layout_post>#post{    /* 以下代表透明度为0.7 */    background: rgba(255,255,255,.9);    border:2px solid #0ff5ff;    box-shadow: 1px 1px 10px #0ff5ff; }/* 侧边卡片的透明度 */:root {  --card-bg: rgba(255, 255, 255, .9);}/* 页脚透明 */#footer {/* 以下代表透明度为0.7 */background: rgba(255,255,255, .0);} :root {    --global-font-size: 20px;}.aplayer .aplayer-list ol li.aplayer-list-light, .aplayer, #aside_content .card-widget, #recent-posts>.recent-post-item, .layout>div:first-child:not(.recent-posts), .layout_post>#page, .layout_post>#post, .read-mode .layout_post>#post{    /* ä»¥ä¸‹ä»£è¡¨ç™½è‰²é€æ˜Žåº¦ä¸º0.3 */    background: rgba(255, 255, 255, 0.9);    border:2px solid #0ff5ff;    box-shadow: 1px 1px 10px #0ff5ff;}   .recent-post-item{    background: rgba(255, 255, 255, 0.9);    border:2px solid #0ff5ff;    box-shadow: 1px 1px 10px #0fffc3;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>醉欢行</title>
      <link href="/%E9%86%89%E6%AC%A2%E8%A1%8C/index.html"/>
      <url>/%E9%86%89%E6%AC%A2%E8%A1%8C/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>水调歌头</title>
      <link href="/poem/%E6%B0%B4%E8%B0%83%E6%AD%8C%E5%A4%B4.html"/>
      <url>/poem/%E6%B0%B4%E8%B0%83%E6%AD%8C%E5%A4%B4.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>隐藏在时光里的回忆</title>
      <link href="/%E5%9B%9E%E5%BF%86/index.html"/>
      <url>/%E5%9B%9E%E5%BF%86/index.html</url>
      
        <content type="html"><![CDATA[<h1 id="序-回忆璀璨如花"><a href="#序-回忆璀璨如花" class="headerlink" title="序 回忆璀璨如花"></a><strong>序 回忆璀璨如花</strong></h1><p>嵊县的秋季格外凉爽，兴许是军训的后遗症，又或许是因为全球变暖让楚宇这颗心系世和平的心莫名的烦躁，趁老师不注意，趴在桌子上百无聊赖地望着窗外一片一片下落的银杏。</p><p>还没多看几眼便被一旁的男生用笔戳了戳腰，</p><p>“别发呆了，我看君姐已经瞥了你好几眼了，你是真喜欢上她办公室的龙井了？”</p><p>楚宇稍微起了起身子，给同桌翻了个白眼，露出手肘下面的翻在《荷塘月色》一面的语文书，</p><p>“啧，我这可不叫发呆，我只是在体会朱自清先生‘什么都可以想，什么都可以不想’的意境！还有，你这个开学没多久就因为上课看小说跟老师混熟的也没资格说我吧。”</p><p>说罢，楚宇还翘起嘴巴，用下巴点了点同桌本子下藏着的《花火》。</p><p>“但我成绩全班前三。”面对楚宇的挑衅，其同桌轻描淡写地答道。</p><p>楚宇忍住想要怒拍桌子的手，声音低沉地抗议，“难道成绩好就可以为所欲为吗!气抖冷，学渣什么时候才能站起来！”</p><p>同桌翻了翻白眼，道：“呵，站起来也给你腿打折，而且，成绩好确实可以为所欲为。”</p><p>楚宇刚要开口怼回去，就听得讲台上一阵河东狮吼传过：“楚宇，江耿给我站起来！楚宇，你来回答荷塘月色一共分为几部分，分别用几幅图来概括各部分内容。</p><p>楚宇回答不出来，江耿接着，要是都不会，这节课就站着吧。”</p><p>这两同桌一个发呆，一个看小说，最终结果自然是全军覆没。</p><p>当君姐重新开始上课时，两人不约而同的侧向对方，骂道：</p><p>“还不都是因为你！”</p><p>“还不都是因为你！”</p><p>……..</p><p>“向前跑！</p><p>迎着眼泪和嘲笑，</p><p>生命的广阔不经历风雨怎能感到…….”</p><p>一阵手机铃声将楚宇从睡梦中惊醒，楚宇左脚一踹，碰到守株待兔的墙壁，顿时缩进被窝里裹成史莱姆状，捂着脚指头瑟瑟发抖，将刚刚响铃抛之脑后。</p><p>但是电话铃却是不肯停歇，没一会又响了起来。</p><p>史莱姆状的被窝先是沉寂几秒钟，然后被色史莱姆缓缓向床头蠕动，伸出一只手，摸到床头的手机，看了看联系人，不耐烦地接到：“喂，徐正言！不知道放假人，人上人，扰人清梦可是大忌啊！”</p><p>“……”电话那先是一阵沉默，随即传来一阵怒吼，“你是不是忘了今天还要回学校！再不过来，老张就要来亲自问候您了！”</p><p>本还在撞墙以及起床气双重debuff中的楚宇听到“老张”二字突然清醒，瞥了一眼手机上的时间日期，顾不得留恋温暖的被窝，毫无形象地从床上爬起。</p><p>…………</p><p>紧赶慢赶，当楚宇冲进教室时，老张似乎还没到，同学们三三两两地坐一块，毕竟也算是高中毕业了，多数人都是把手机带来了。有王者开黑的，有聚在一块插科打诨的，嗯，也有刚毕业就斥巨资买了个索尼新款耳机然后就整天机不离手不知道搁那听啥的憨憨。</p><p>楚宇径直地走向自己座位，把同桌的耳机摘了下来，戴到了自己耳朵上，听着耳机中传来林肯公园的《In The End》，向徐正言问道：</p><p>“老张有没有来过？毕业典礼啥时候开始啊？”</p><p>兴许是对楚宇拿耳机的不爽，楚宇面对徐正言故意光张嘴不说话的幼稚行为，大声回怼：</p><p>“你刚电话里不说的顶凶？现在见面了不敢说话了？”</p><p>徐正言显然是不知道楚宇会这么回答，先是一怔，然后一把把耳机从楚宇头上摘下，</p><p>“他喵的你带着降噪耳机跟我说话你是想咋样啊喂，还我不敢说话，你怎么这么能啊！我……”</p><p>还没等徐正言骂完，班主任张德新出现在门口，走进教室，不得不说即使毕业了，班主任的威严是丝毫不减，班里瞬间鸦雀无声，玩手机的也不自觉的把手机藏了藏。徐正言白了楚宇一眼，也正了正身子。</p><p>“今天的流程十分简短，等你们听完毕业典礼，回来自己整完书就可以回去了。</p><p>去之前让我再唠叨几句，高考前，总是抓着你们念，高考是你们转折点，反复提醒，显得高考失败人生都输了似的，</p><p>现在肯定不会这么说，哪怕你高考失利，大学只要加把劲，考研也能考一个好学校……”</p><p>老班这段透着“主要唠叨会随当前情境改变”变相劝学的言论，不由得引起同学们的轻笑。</p><p>楚宇也放松起来，身子趴在桌上，看着讲台上还在念叨的老班，好笑又有些伤感的想到，</p><p>“都毕业了还是不忘催我们去学习啊。”</p><p>开学典礼，学生大会，结业典礼……三年来在学校参加的数不胜数的会典都是大同小异，校长演讲，表扬，鸡汤等等。无论是经历过学生时代，还是正处于青春对此想必都耳熟能详。</p><p>许是老张难得没敷衍我们，典礼流程确实简短，也有可能是有着手机打发时间，转眼间典礼就结束了，同学们闹哄哄地跑向教室，边跑边跟着一旁的同学吐槽，</p><p>“学校？我可是不能多待一秒！冲冲冲！”</p><p>徐正言也是手脚利落，三下五除二便把书整理好，见楚宇坐在位置上看着手机发呆，用力拍了一下楚宇的背，顺势将头一伸，</p><p>“跟哪个妹纸聊天呢？书都还没整完？”</p><p>但显然是楚宇熄屏键按得更快，待徐正言定睛看清，只能看到黑屏上倒映的自己。</p><p>楚宇没好气地说道：“就你整天爱吃瓜，我哪像你这么不爱学习书这么少，我爸妈还没到呢，咱整完书也没地放。”</p><p>徐正言对这种高考完一点书不整直接奔回家，现在还如此理直气壮的行为不做表示，向楚宇挥了挥手，留下句，“暑假聚”，转身离去，只给楚宇留下个后脑勺。</p><p>过了没多久，楚宇趁着父母没到，带着早上匆忙拿来的袋子也走出了教室。</p><p>…………</p><p>窗外树影婆娑，木槿摇曳，朦胧的月色星光不知被何人碾碎，织起一浣轻纱，平铺在天空之中。</p><p>夏日的夜晚仍是可以清凉的，楚宇坐在书桌前，感受着一阵阵微风拂来，看着桌上的日记本。</p><p>这是楚宇下午整理出来的，刚翻出来时，它混杂在一堆教科书作业本中，虽然高考前三个月完全忘记了日记这回事，将其埋没于书海中，1但意外地没有褶皱，安静地躺着，像是隐藏在时光中似的。</p><p>花了几个小时把整本日记浏览了一遍，然后在开头故意留出的空白的一页提笔写下，</p><p>回忆璀璨如花</p><h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a><strong>第一章</strong></h1><p>八月末的阳光格外的毒辣，原本清凉的早晨的微风也带着一丝燥热，几只飞鸟路过，穿过如今已愈发少见的喷气式飞机留下的痕迹，此时知了的精力最是旺盛，阳光透过树叶形成斑驳的小圆影，打在鸣叫的知了上，宛若为其穿上了新衣。</p><p>原本安逸的校园因为一些“不速之客”打破了此时祥和的氛围。</p><p>“砰！”</p><p>楚宇用自己的身体将虚掩着的门撞开，灰尘扬起，在阳光的照射下格外显眼，如同精灵般飞舞着。</p><p>拿着大包小包的楚宇平复着略微有点喘的呼吸，心里念叨着，</p><p>“嘁，出师不利，七点多就来学校不说，刚入学就让我爬六楼给我来个下马威是吧，以后放学已经不想回寝室了。”</p><p>若是能回到前一天晚上，他一定会把那个义正严词地拒绝了母亲想要来帮忙搬运行李的请求，拍着胸脯发誓一个人也能搞定的自己打一顿，然后哭求妈妈再爱我一次。</p><p>当然这些臆想也就一闪而过，毕竟还有一堆行李要整，他回过神仔细环顾了四周，将自己未来几年居住的寝室布局纳入眼帘：</p><p>抬头正对门的便是卫生间，储物柜在入门左手，兴许因为是c形楼最边上的寝室，与先前瞥到的别的寝室床、柜子、卫生间堆挤在一个房间的布局不同，楚宇寝室的储物柜与卫生间独立在一个隔间，右手的过道穿过个约一人半长宽的门形口子才到摆放着几张双人床的“住宿区”，过道的尽头便是阳台。</p><p>楚宇粗略地扫了一眼过道，虽然寝室许久没有人，但看起来还是蛮干净的。先前自己还担忧得废些力气才能打扫完工。</p><p>待楚宇拖着行李箱以及装着被褥的寝室袋进去寝室，才发现寝室这么干净是有原因的——有位男生在阳台死角上，似是听到动静，正好冒出个头，望向楚宇。</p><p>阳台的窗户开着，一阵微风拂过，吹起男生的碎发，那位男生似是双腿一蹬，楚宇便看到男生“咕噜，咕噜”的坐着行李箱划了出来，他从行李箱小跳了下来，面带微笑地走过来帮忙拿行李，说道：</p><p>“你也是601的吧？我叫江耿，将来几年就好好相处喽！”</p><p>“谢谢帮忙，额……我叫楚宇。”楚宇表面上没有异样，但心里完全任由吐槽本能爆发。</p><p>“啧啧，可恶啊，热情开朗还长得小帅，妥妥的人生赢家模板啊，唯一的不足是身高似乎只有170出头，嗯比我矮好些。”</p><p>楚宇自然也知道身高的比较只是毫无意义的逞强，但是男人的迷之胜负欲就是如此，孔子都说三人行必有我师，自己总得有些比得过人家的方面是吧。</p><p>虽说楚宇思绪越飘越远，但手上没闲着，找到自己靠阳台侧上铺的床位，将一些行李放在上面。</p><p>说来也巧，另一旁的上铺的被褥也已经整理好了，不用多想也能猜到这就是那位江耿同学的床位。</p><p>兴许是江耿在阳台的活也干完了，他并没有回阳台继续捣鼓，而是打开行李箱整理衣服。楚宇也开始了整理被褥、铺床，短短几分钟，601寝室便出现了安静—热闹—寂静的不同氛围，没错，你没看错就是寂静，若是江耿继续回阳台干活，楚宇倒也不会怎么样，但当其也在“住宿区”整理时，两者皆不说话的氛围就让楚宇有些待不住了，感觉气氛一度凝固。当楚宇快忍不住，准备找些垃圾话活跃活跃气氛时，江耿也发话了：</p><p>“学校规定的是九点半到校吧，这才七点出头，你为什么来的这么早？要不是尚东那的公交车来城里只有六点多的，我现在还睡着呢！”</p><p>闻言，楚宇也是暗松了口气，在听到江耿是尚东的后，也了然原因，楚宇父亲也是尚东镇的，偶尔自驾来回一趟便要花费不少时间，更别说是坐城乡公交车了，导致平日里那边公交车的排班确实不多。楚宇没放下手中的工作，边整理边回答：</p><p>“”</p>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>诗词</title>
      <link href="/poem/index.html"/>
      <url>/poem/index.html</url>
      
        <content type="html"><![CDATA[<div class="note icon-padding simple"><i class="note-icon fab fa-cc-visa"></i><p>你是刷 Visa 還是 UnionPay</p></div><div class="note blue icon-padding simple"><i class="note-icon fas fa-bullhorn"></i><p>2021年快到了….</p></div><div class="note pink icon-padding simple"><i class="note-icon fas fa-car-crash"></i><p>小心開車 安全至上</p></div><div class="note red icon-padding simple"><i class="note-icon fas fa-fan"></i><p>這是三片呢？還是四片？</p></div><div class="note orange icon-padding simple"><i class="note-icon fas fa-battery-half"></i><p>你是刷 Visa</p></div><div class="note purple icon-padding simple"><i class="note-icon far fa-hand-scissors"></i><p>剪刀石頭布</p></div><div class="note green icon-padding simple"><i class="note-icon fab fa-internet-explorer"></i><p>前端最討厭的瀏覽器</p></div>]]></content>
      
    </entry>
    
    
  
</search>
